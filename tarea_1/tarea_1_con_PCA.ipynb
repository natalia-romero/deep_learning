{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpGNMWyYycUh"
      },
      "source": [
        "---\n",
        "# Tarea 1 Deep Learning\n",
        "- Integrantes: Matias Aguilera, Jonas Oviedo y Natalia Romero\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3T8z8iJycUk"
      },
      "source": [
        "### Importar librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "SrrUcFEIycUl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3Q6XxygycUn"
      },
      "source": [
        "### Función para calcular distribución de clases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "A7781Ts1ycUo"
      },
      "outputs": [],
      "source": [
        "def classes_distribution(arr):\n",
        "    # Calculate the count of TRUE and FALSE\n",
        "    count_true = np.count_nonzero(arr)\n",
        "    count_false = arr.size - count_true\n",
        "\n",
        "    # Calculate the percentage of TRUE and FALSE\n",
        "    percent_true = (count_true / arr.size) * 100\n",
        "    percent_false = (count_false / arr.size) * 100\n",
        "\n",
        "    print(f\"TRUE: {count_true} ({percent_true:.2f}%)\")\n",
        "    print(f\"FALSE: {count_false} ({percent_false:.2f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeB_-v-OycUo"
      },
      "source": [
        "### Implementación de Logistic Regression\n",
        "La implementación se basa en el articulo de Medium \"Logistic Regression From Scratch\"\n",
        "\n",
        "\n",
        "\n",
        "Kushal, K. (Fecha de publicación). Logistic Regression from Scratch. Medium. https://medium.com/@koushikkushal95/logistic-regression-from-scratch-dfb8527a4226"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "N1bmccZcycUp"
      },
      "outputs": [],
      "source": [
        "class LogisticRegression:\n",
        "    def __init__(self, learning_rate=0.001, n_iters=1000):\n",
        "        self.lr = learning_rate\n",
        "        self.n_iters = n_iters\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "        self.losses = []\n",
        "\n",
        "    #Sigmoid method\n",
        "    def _sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def compute_loss(self, y_true, y_pred):\n",
        "        # binary cross entropy\n",
        "        epsilon = 1e-9\n",
        "        y1 = y_true * np.log(y_pred + epsilon)\n",
        "        y2 = (1-y_true) * np.log(1 - y_pred + epsilon)\n",
        "        return -np.mean(y1 + y2)\n",
        "\n",
        "    def feed_forward(self,X):\n",
        "        z = np.dot(X, self.weights) + self.bias\n",
        "        A = self._sigmoid(z)\n",
        "        return A\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        # Initialize parameters\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        # Gradient descent\n",
        "        for _ in range(self.n_iters):\n",
        "            A = self.feed_forward(X)\n",
        "            loss = self.compute_loss(y, A)  # Compute current loss\n",
        "            self.losses.append(loss)  # Record the loss\n",
        "\n",
        "            dz = A - y  # Derivative of loss w.r.t. predictions\n",
        "            dw = (1 / n_samples) * np.dot(X.T, dz)\n",
        "            db = (1 / n_samples) * np.sum(dz)\n",
        "\n",
        "            # Update parameters\n",
        "            self.weights -= self.lr * dw\n",
        "            self.bias -= self.lr * db\n",
        "\n",
        "    def predict(self, X):\n",
        "        threshold = 0.5\n",
        "        y_hat = np.dot(X, self.weights) + self.bias\n",
        "        y_predicted = self._sigmoid(y_hat)\n",
        "        y_predicted_cls = np.array([1 if i > threshold else 0 for i in y_predicted])\n",
        "        ids = np.arange(len(y_predicted_cls))\n",
        "        arr = np.core.records.fromarrays([ids, y_predicted_cls], names='ID,Class')\n",
        "        return arr\n",
        "\n",
        "    def plot_loss(self):\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(self.losses, label='Loss')\n",
        "        plt.title('Loss vs. Iterations')\n",
        "        plt.xlabel('Iterations')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lda(X, y, n_components):\n",
        "    class_means = []\n",
        "    for c in np.unique(y):\n",
        "        class_means.append(np.mean(X[y == c], axis=0))\n",
        "\n",
        "    overall_mean = np.mean(X, axis=0)\n",
        "    within_class_scatter = np.zeros((X.shape[1], X.shape[1]))\n",
        "\n",
        "    for c, mean in zip(np.unique(y), class_means):\n",
        "        class_scatter = np.zeros((X.shape[1], X.shape[1]))\n",
        "        for row in X[y == c]:\n",
        "            row, mean = row.reshape(X.shape[1], 1), mean.reshape(X.shape[1], 1)\n",
        "            class_scatter += np.dot((row - mean), (row - mean).T)\n",
        "        within_class_scatter += class_scatter\n",
        "\n",
        "    between_class_scatter = np.zeros((X.shape[1], X.shape[1]))\n",
        "    for mean in class_means:\n",
        "        mean = mean.reshape(X.shape[1], 1)\n",
        "        between_class_scatter += np.dot((mean - overall_mean), (mean - overall_mean).T)\n",
        "\n",
        "    eigenvalues, eigenvectors = np.linalg.eig(np.dot(np.linalg.inv(within_class_scatter), between_class_scatter))\n",
        "    sorted_indices = np.argsort(eigenvalues.real)[::-1]\n",
        "    selected_indices = sorted_indices[:n_components]\n",
        "    linear_discriminants = np.hstack(eigenvectors[:, index].reshape(X.shape[1], 1) for index in selected_indices)\n",
        "    X_lda = np.dot(X, linear_discriminants)\n",
        "\n",
        "    return X_lda\n",
        "\n",
        "def pca(X, n_components):\n",
        "    # 1. Normalización de datos\n",
        "    X_normalized = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
        "\n",
        "    # 2. Cálculo de la matriz de covarianza\n",
        "    covariance_matrix = np.cov(X_normalized, rowvar=False)\n",
        "\n",
        "    # 3. Cálculo de autovalores y autovectores\n",
        "    eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n",
        "\n",
        "    # 4. Selección de componentes principales\n",
        "    sorted_indices = np.argsort(eigenvalues)[::-1]  # Orden descendente\n",
        "    selected_indices = sorted_indices[:n_components]\n",
        "    principal_components = eigenvectors[:, selected_indices]\n",
        "\n",
        "    # 5. Transformación de datos\n",
        "    X_transformed = np.dot(X_normalized, principal_components)\n",
        "    return X_transformed"
      ],
      "metadata": {
        "id": "TH3k-iWI81Mw"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDvrauDYycUq"
      },
      "source": [
        "### Train Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "Xrf3fL7vycUr",
        "outputId": "381f668a-e3d5-42db-d492-b25c394bed00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRUE: 1450 (39.40%)\n",
            "FALSE: 2230 (60.60%)\n"
          ]
        }
      ],
      "source": [
        "train = np.genfromtxt('train_data.csv', delimiter=',', skip_header=1)\n",
        "X_train = train[:, :-1]\n",
        "X_train = (X_train - np.mean(X_train, axis=0)) / np.std(X_train, axis=0)\n",
        "y_train = train[:, -1]\n",
        "classes_distribution(y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5APBM1MqycUt"
      },
      "source": [
        "### Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "MNgpCWLrycUu"
      },
      "outputs": [],
      "source": [
        "test = np.genfromtxt('test_data.csv', delimiter=',', skip_header=1)\n",
        "X_test = test[:, :-1]\n",
        "X_test = (X_test - np.mean(X_test, axis=0)) / np.std(X_test, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkZxzKfxycUv"
      },
      "source": [
        "### Entrenando el modelo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aplicando funcion de reduccion de features (PCA)"
      ],
      "metadata": {
        "id": "49RGYGxNGM_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Aplicar PCA\n",
        "n_components = 30  # Define el número de componentes principales\n",
        "X_train_pca = pca(X_train, n_components)\n",
        "X_test_pca = pca(X_test, n_components)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "nOn_9G9fB7R1",
        "outputId": "be5a1677-ea29-4930-ddd4-fb28af9cb028"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "arrays to stack must be passed as a \"sequence\" type such as list or tuple.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-5b9cd460d737>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_test_pca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX_train_lda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mX_test_lda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-72-68667689f300>\u001b[0m in \u001b[0;36mlda\u001b[0;34m(X, y, n_components)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0msorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meigenvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mselected_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mlinear_discriminants\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meigenvectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselected_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mX_lda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinear_discriminants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36m_vhstack_dispatcher\u001b[0;34m(tup, dtype, casting)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_vhstack_dispatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_arrays_for_stack_dispatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36m_arrays_for_stack_dispatcher\u001b[0;34m(arrays)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_arrays_for_stack_dispatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitem__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         raise TypeError('arrays to stack must be passed as a \"sequence\" type '\n\u001b[0m\u001b[1;32m    210\u001b[0m                         'such as list or tuple.')\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: arrays to stack must be passed as a \"sequence\" type such as list or tuple."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nM-NnljRycUv"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Entrenar y probar el modelo de regresión logística con datos transformados\n",
        "logistic_regression = LogisticRegression(learning_rate=0.09, n_iters=1500)\n",
        "#PCA\n",
        "#logistic_regression.fit(X_train_pca, y_train)\n",
        "#predictions = logistic_regression.predict(X_test_pca)\n",
        "#Normal\n",
        "#logistic_regression.fit(X_train, y_train)\n",
        "#predictions = logistic_regression.predict(X_test)\n",
        "#LDA\n",
        "logistic_regression.fit(X_train_lda, y_train)\n",
        "predictions = logistic_regression.predict(X_test_lda)\n",
        "\n",
        "\n",
        "\n",
        "np.savetxt(\"submission.csv\", predictions, delimiter=\",\", fmt='%d', header=\"ID,Class\", comments='')\n",
        "logistic_regression.plot_loss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IljI1FqTycUw"
      },
      "source": [
        "### Cálculo de métricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnJhrdulycUw"
      },
      "outputs": [],
      "source": [
        "def calculate_metrics(y_true, y_pred):\n",
        "    # true positives, false positives, true negatives, and false negatives\n",
        "    tp = np.sum((y_pred == 1) & (y_true == 1))\n",
        "    tn = np.sum((y_pred == 0) & (y_true == 0))\n",
        "    fp = np.sum((y_pred == 1) & (y_true == 0))\n",
        "    fn = np.sum((y_pred == 0) & (y_true == 1))\n",
        "\n",
        "    # metrics\n",
        "    accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFcEuwoDycUw"
      },
      "source": [
        "### K-Fold Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54rJgH-AycUw"
      },
      "outputs": [],
      "source": [
        "def k_fold_split(X, y, k):\n",
        "    n_samples = len(y)\n",
        "    indices = np.arange(n_samples)\n",
        "    np.random.shuffle(indices)\n",
        "    fold_sizes = np.full(k, n_samples // k)\n",
        "    fold_sizes[:n_samples % k] += 1\n",
        "    current = 0\n",
        "    folds = []\n",
        "    for fold_size in fold_sizes:\n",
        "        start, stop = current, current + fold_size\n",
        "        folds.append((indices[start:stop]))\n",
        "        current = stop\n",
        "    return folds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRU32OdRycUx"
      },
      "outputs": [],
      "source": [
        "def cross_validation(X, y, k=5, learning_rate=0.09, n_iters=1500):\n",
        "    folds = k_fold_split(X, y, k)\n",
        "    scores = []\n",
        "    for i in range(k):\n",
        "        train_i = np.hstack([folds[j] for j in range(k) if j != i])\n",
        "        test_i = folds[i]\n",
        "        X_train, y_train = X[train_i], y[train_i]\n",
        "        X_test, y_test = X[test_i], y[test_i]\n",
        "        lr = LogisticRegression(learning_rate, n_iters)\n",
        "        lr.fit(X_train, y_train)\n",
        "        predictions = lr.predict(X_test)\n",
        "        score = calculate_metrics(predictions['Class'],y_test)\n",
        "        scores.append(score)\n",
        "        print(f\"Fold {i+1}, Score: {score}\")\n",
        "        lr.plot_loss()\n",
        "        print(\"----------------\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjwxtbtnycUx"
      },
      "outputs": [],
      "source": [
        "cross_validation(X_train,y_train)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}